<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AURA-X Î© â€“ Emotional Continuity Prototype</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    *{box-sizing:border-box;margin:0;padding:0}
    html,body{height:100%}
    body{
      font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",sans-serif;
      background:
        radial-gradient(circle at 20% 0%, #0f172a 0, transparent 45%),
        radial-gradient(circle at 80% 0%, #0ea5e9 0, transparent 40%),
        linear-gradient(145deg,#020617 0,#020617 40%,#020617 100%);
      color:#e5e7eb;
      display:flex;
      justify-content:center;
      align-items:flex-start;
      padding:20px;
    }
    .app{
      width:100%;
      max-width:1100px;
      background:#020617dd;
      border-radius:24px;
      box-shadow:0 24px 60px rgba(15,23,42,.65);
      padding:20px;
      display:grid;
      grid-template-columns:minmax(0,3fr) minmax(0,2.2fr);
      gap:18px;
    }
    @media(max-width:900px){
      .app{grid-template-columns:minmax(0,1fr)}
    }

    /* HEADER */
    .header{
      grid-column:1 / -1;
      display:flex;
      justify-content:space-between;
      align-items:flex-start;
      gap:12px;
      margin-bottom:6px;
    }
    .brand{
      display:flex;
      flex-direction:column;
      gap:4px;
    }
    .title{
      font-size:1.25rem;
      letter-spacing:.06em;
      text-transform:uppercase;
      font-weight:600;
      color:#e5e7ff;
    }
    .subtitle{
      font-size:.72rem;
      opacity:.75;
    }
    .ethics{
      font-size:.7rem;
      max-width:340px;
      line-height:1.3;
      padding:6px 10px;
      border-radius:999px;
      border:1px solid rgba(250,204,21,.65);
      background:linear-gradient(90deg,rgba(24,24,27,.7),rgba(23,37,84,.4));
      color:#facc15;
    }

    /* BUTTONS */
    .header-buttons{
      display:flex;
      gap:8px;
      align-items:center;
    }
    .btn{
      border:none;
      border-radius:999px;
      padding:6px 12px;
      font-size:.75rem;
      display:inline-flex;
      gap:6px;
      align-items:center;
      cursor:pointer;
      background:rgba(15,23,42,.9);
      color:#e5e7eb;
      box-shadow:0 0 0 1px rgba(148,163,184,.5);
      transition:background .16s,transform .12s,box-shadow .16s;
    }
    .btn span.icon{font-size:.9rem}
    .btn:hover{
      background:rgba(30,64,175,.95);
      box-shadow:0 0 0 1px rgba(191,219,254,.9),0 10px 25px rgba(15,23,42,.6);
      transform:translateY(-1px);
    }
    .btn-secondary{
      background:rgba(15,23,42,.8);
      box-shadow:0 0 0 1px rgba(75,85,99,.9);
    }

    /* LEFT COLUMN â€“ CHAT */
    .chat-card{
      background:radial-gradient(circle at top,#0b1220 0,#020617 60%);
      border-radius:20px;
      padding:14px 14px 12px;
      display:flex;
      flex-direction:column;
      gap:10px;
      border:1px solid rgba(148,163,184,.4);
      position:relative;
      overflow:hidden;
    }
    .chat-header{
      display:flex;
      justify-content:space-between;
      align-items:center;
      font-size:.72rem;
      opacity:.8;
    }
    .chat-header strong{font-size:.78rem}
    .tm-tag{
      padding:2px 8px;
      border-radius:999px;
      background:rgba(37,99,235,.18);
      border:1px solid rgba(129,140,248,.7);
      font-size:.65rem;
      text-transform:uppercase;
      letter-spacing:.08em;
    }
    .chat-log{
      max-height:420px;
      min-height:240px;
      overflow:auto;
      padding-right:4px;
      display:flex;
      flex-direction:column;
      gap:8px;
      scrollbar-width:thin;
    }
    .msg{
      display:flex;
      flex-direction:column;
      max-width:100%;
      font-size:.8rem;
    }
    .msg.user{align-items:flex-end}
    .msg.ai{align-items:flex-start}
    .bubble{
      padding:7px 10px;
      border-radius:14px;
      line-height:1.35;
      max-width:92%;
      word-wrap:break-word;
    }
    .msg.user .bubble{
      background:linear-gradient(135deg,#22c55e,#16a34a);
      color:#022c22;
      border-bottom-right-radius:4px;
    }
    .msg.ai .bubble{
      background:rgba(15,23,42,.9);
      border:1px solid rgba(148,163,184,.6);
      border-bottom-left-radius:4px;
    }
    .msg-meta{
      font-size:.62rem;
      opacity:.6;
      margin-top:2px;
      display:flex;
      gap:6px;
      align-items:center;
    }
    .emo-dot{
      width:7px;height:7px;
      border-radius:50%;
      box-shadow:0 0 0 1px rgba(15,23,42,.9);
    }

    /* INPUT AREA */
    .input-area{
      margin-top:6px;
      display:flex;
      gap:8px;
      align-items:flex-end;
    }
    .input-shell{
      flex:1;
      background:rgba(15,23,42,.95);
      border-radius:18px;
      border:1px solid rgba(55,65,81,.9);
      display:flex;
      align-items:center;
      padding:6px 10px;
      position:relative;
    }
    .input-shell::before{
      content:"TM = user input + helper LLM answer (for future)";
      position:absolute;
      top:-15px;
      left:14px;
      font-size:.6rem;
      opacity:.5;
    }
    .input{
      flex:1;
      border:none;
      outline:none;
      background:transparent;
      color:#e5e7eb;
      font-size:.8rem;
      padding:3px 0;
      resize:none;
      max-height:80px;
    }
    .send-btn{
      border:none;
      background:linear-gradient(135deg,#38bdf8,#6366f1);
      color:white;
      border-radius:999px;
      padding:6px 9px;
      display:flex;
      align-items:center;
      justify-content:center;
      cursor:pointer;
      font-size:.9rem;
      box-shadow:0 10px 30px rgba(56,189,248,.4);
    }
    .send-btn:disabled{
      opacity:.4;
      box-shadow:none;
      cursor:default;
    }

    /* RIGHT COLUMN â€“ METRICS */
    .right-col{
      display:flex;
      flex-direction:column;
      gap:12px;
    }
    .card{
      background:radial-gradient(circle at top,#020617,#020617 55%);
      border-radius:18px;
      padding:12px 14px;
      border:1px solid rgba(148,163,184,.45);
    }
    .card-title{
      font-size:.78rem;
      text-transform:uppercase;
      letter-spacing:.08em;
      opacity:.7;
      margin-bottom:6px;
    }

    /* Gauge */
    .gauge-wrap{
      display:flex;
      align-items:center;
      gap:10px;
    }
    .gauge{
      width:120px;
      height:60px;
      border-radius:120px 120px 8px 8px;
      background:conic-gradient(
        from 180deg,
        #ef4444 0deg,
        #f97316 60deg,
        #eab308 115deg,
        #22c55e 180deg
      );
      position:relative;
      overflow:hidden;
      box-shadow:0 12px 30px rgba(15,23,42,.8);
    }
    .gauge-inner{
      position:absolute;
      inset:8px;
      border-radius:999px;
      background:#020617;
    }
    .needle{
      position:absolute;
      width:2px;
      height:54px;
      background:#e5e7eb;
      left:50%;
      bottom:6px;
      transform-origin:50% 100%;
      transform:rotate(0deg);
      transition:transform .35s ease-out;
      box-shadow:0 0 6px rgba(248,250,252,.9);
    }
    .gauge-labels{
      display:flex;
      justify-content:space-between;
      font-size:.6rem;
      opacity:.6;
      margin-top:4px;
    }
    .gauge-info{
      font-size:.7rem;
      opacity:.8;
      line-height:1.25;
    }

    /* BM ORB */
    .bm-orb-wrap{
      display:flex;
      align-items:center;
      gap:12px;
    }
    .bm-orb{
      width:70px;height:70px;
      border-radius:50%;
      background:radial-gradient(circle at 30% 20%,#facc15,transparent 60%),
                 radial-gradient(circle at 80% 80%,#22c55e,transparent 60%),
                 radial-gradient(circle at 10% 80%,#0ea5e9,transparent 55%),
                 #020617;
      box-shadow:0 0 18px rgba(52,211,153,.6);
      animation:pulse 4s ease-in-out infinite;
    }
    @keyframes pulse{
      0%,100%{transform:scale(1);box-shadow:0 0 18px rgba(52,211,153,.5);}
      50%{transform:scale(1.06);box-shadow:0 0 28px rgba(52,211,153,.9);}
    }
    .bm-info{
      font-size:.7rem;
      line-height:1.3;
      opacity:.86;
    }

    /* HISTORY */
    .history-log{
      max-height:180px;
      overflow:auto;
      font-size:.7rem;
      line-height:1.3;
      padding-right:4px;
      scrollbar-width:thin;
    }
    .hist-item{
      padding:4px 0;
      border-bottom:1px dashed rgba(55,65,81,.8);
    }
    .hist-item:last-child{border-bottom:none}
    .hist-item strong{font-size:.7rem}

    /* MODAL */
    .modal-overlay{
      position:fixed;
      inset:0;
      background:rgba(15,23,42,.6);
      display:none;
      justify-content:center;
      align-items:center;
      z-index:40;
    }
    .modal{
      width:100%;
      max-width:440px;
      background:#020617;
      border-radius:20px;
      box-shadow:0 24px 80px rgba(15,23,42,.9);
      border:1px solid rgba(148,163,184,.6);
      padding:14px 16px 16px;
      font-size:.78rem;
    }
    .modal-header{
      display:flex;
      justify-content:space-between;
      align-items:center;
      margin-bottom:8px;
    }
    .modal-title{font-size:.86rem;font-weight:600}
    .close-btn{
      border:none;
      background:transparent;
      color:#9ca3af;
      font-size:1.1rem;
      cursor:pointer;
    }
    .section-label{
      font-size:.72rem;
      text-transform:uppercase;
      letter-spacing:.08em;
      opacity:.8;
      margin:8px 0 4px;
    }
    .field-label{
      font-size:.72rem;
      opacity:.78;
      margin-top:6px;
      margin-bottom:2px;
    }
    .field{
      width:100%;
      border-radius:10px;
      border:1px solid rgba(55,65,81,.9);
      background:#020617;
      color:#e5e7eb;
      padding:6px 8px;
      font-size:.75rem;
      outline:none;
    }
    .field::placeholder{opacity:.4}
    .modal-actions{
      margin-top:10px;
      display:flex;
      gap:8px;
      align-items:center;
      justify-content:flex-start;
      flex-wrap:wrap;
    }
    .tag{
      padding:3px 8px;
      border-radius:999px;
      border:1px solid rgba(75,85,99,.9);
      font-size:.65rem;
      opacity:.8;
    }
    .toggle-row{
      display:flex;
      align-items:center;
      gap:6px;
      margin-top:6px;
      font-size:.72rem;
      opacity:.9;
    }
    .progress-bar{
      margin-top:5px;
      width:100%;
      height:6px;
      border-radius:999px;
      background:rgba(31,41,55,.9);
      overflow:hidden;
    }
    .progress-bar-inner{
      width:0%;
      height:100%;
      background:linear-gradient(90deg,#22c55e,#a3e635);
      transition:width .2s ease-out;
    }
    .status-text{
      font-size:.7rem;
      margin-top:3px;
      opacity:.85;
    }
    .pill-ok{color:#4ade80}
    .pill-error{color:#f97373}
    .pill-warn{color:#facc15}
  </style>
</head>
<body>
<div class="app">
  <header class="header">
    <div class="brand">
      <div class="title">AURA-X Î©</div>
      <div class="subtitle">Artificial Unified Resonance Architecture â€“ Emotional Continuity Prototype</div>
    </div>
    <div class="header-buttons">
      <div class="ethics">
        Avoid actions that create strong negative emotions in you or others, and gently move toward actions that spread stable, constructive positivity.
      </div>
      <button class="btn" id="btnHistory"><span class="icon">ðŸ§ </span>History</button>
      <button class="btn btn-secondary" id="btnLLM"><span class="icon">ðŸ¤–</span>LLM link</button>
    </div>
  </header>

  <!-- LEFT: CHAT -->
  <section class="chat-card">
    <div class="chat-header">
      <div><strong>Dialogue</strong> Â· AURA-X Î© mini-engine + helper LLM</div>
      <div class="tm-tag">TM stream</div>
    </div>
    <div id="chatLog" class="chat-log"></div>
    <div class="input-area">
      <div class="input-shell">
        <textarea id="userInput" class="input" rows="1" placeholder="Type naturally here..."></textarea>
        <button id="sendBtn" class="send-btn">âž¤</button>
      </div>
    </div>
  </section>

  <!-- RIGHT: METRICS -->
  <section class="right-col">
    <div class="card">
      <div class="card-title">Continuity Reflex â€“ Eâ‚€</div>
      <div class="gauge-wrap">
        <div class="gauge">
          <div class="gauge-inner"></div>
          <div id="needle" class="needle"></div>
        </div>
        <div class="gauge-info">
          <div id="e0Value">Eâ‚€ â‰ˆ 0.00</div>
          <div id="e0Label">Neutral synthetic emotion</div>
          <div id="e0Sources" style="font-size:.68rem;opacity:.7;margin-top:4px;">
            R(TM,BM) wave resonance, decay D, and Î»-faith / Î»-sys / Î»-trc all active.
          </div>
        </div>
      </div>
      <div class="gauge-labels">
        <span>Very negative</span><span>Neutral</span><span>Very positive</span>
      </div>
    </div>

    <div class="card">
      <div class="card-title">BM resonance orb</div>
      <div class="bm-orb-wrap">
        <div id="bmOrb" class="bm-orb"></div>
        <div class="bm-info">
          <div id="bmSummary">BM size: 0 memories Â· resonance R(TM,BM) â‰ˆ 0.00</div>
          <div id="bmContinuity">Continuity index â‰ˆ 0.70 Â· decay D â‰ˆ 0.20</div>
          <div style="margin-top:4px;opacity:.7;">
            Color and glow react to polarity &amp; intensity. Red tones = very negative, blue/green = stable positive, violet = mixed/ambivalent.
          </div>
        </div>
      </div>
    </div>

    <div class="card">
      <div class="card-title">Recent TM â†’ BM trace</div>
      <div id="historyLog" class="history-log"></div>
    </div>
  </section>
</div>

<!-- LLM LINK MODAL -->
<div id="llmModal" class="modal-overlay">
  <div class="modal">
    <div class="modal-header">
      <div>
        <div class="modal-title">ðŸ¤– LLM link &amp; offline engine</div>
        <div style="font-size:.7rem;opacity:.7;">Password 6789 Â· keys stay in this browser only.</div>
      </div>
      <button class="close-btn" id="llmClose">âœ•</button>
    </div>

    <div class="section-label">Offline model (in-browser, WebGPU)</div>
    <div style="font-size:.72rem;opacity:.85;">
      Suggested demo: Llama-3.2-1B-Instruct (~1.3 GB, downloaded once, then runs fully offline).
    </div>
    <button class="btn" id="offlineLoadBtn" style="margin-top:6px;">
      <span class="icon">ðŸ“¥</span>Download / load model
    </button>
    <div class="progress-bar">
      <div id="offlineProgress" class="progress-bar-inner"></div>
    </div>
    <div id="offlineStatus" class="status-text pill-warn">Status: not loaded</div>
    <label class="toggle-row">
      <input type="checkbox" id="useOfflineChk" checked />
      <span>Use offline model when cloud LLM is off or fails</span>
    </label>

    <div class="section-label" style="margin-top:10px;">Cloud API (optional)</div>
    <div style="font-size:.7rem;opacity:.78;margin-bottom:4px;">
      Any endpoint that accepts OpenAI-style <code>POST /chat/completions</code> with <code>model</code>, <code>messages</code>, and <code>api-key</code> header.
    </div>

    <label class="field-label">API base URL</label>
    <input id="apiBase" class="field" placeholder="https://your-llm-endpoint.example.com/v1/chat/completions" />

    <label class="field-label">Model name (optional)</label>
    <input id="apiModel" class="field" placeholder="your-model-name" />

    <label class="field-label">API key</label>
    <input id="apiKey" class="field" placeholder="sk-..." />

    <div class="modal-actions">
      <button class="btn" id="saveLlmSettings"><span class="icon">ðŸ’¾</span>Save settings</button>
      <button class="btn btn-secondary" id="clearKey"><span class="icon">ðŸ§¹</span>Clear key</button>
      <span id="llmStatusPill" class="tag">LLM: OFF</span>
    </div>
    <div style="font-size:.7rem;opacity:.75;margin-top:4px;" id="llmHint">
      No online API key saved. Engine is offline-first. Mini-engine always available as backup.
    </div>
  </div>
</div>

<!-- HISTORY MODAL -->
<div id="historyModal" class="modal-overlay">
  <div class="modal">
    <div class="modal-header">
      <div class="modal-title">ðŸ§  Conversation history (TM log)</div>
      <button class="close-btn" id="histClose">âœ•</button>
    </div>
    <div style="font-size:.72rem;opacity:.78;margin-bottom:6px;">
      Recent TM log (user + system messages). This is what the emotional engine uses for continuity.
    </div>
    <div id="fullHistory" class="history-log" style="max-height:260px;"></div>
    <div class="modal-actions">
      <button class="btn btn-secondary" id="clearLast48">Delete history last 48h</button>
      <button class="btn btn-secondary" id="clearAll">Delete all history</button>
    </div>
  </div>
</div>

<script type="module">
  import { CreateMLCEngine } from "https://esm.run/@mlc-ai/web-llm";

  // ---------- STATE ----------
  const state = {
    messages: [],     // {role, text, ts, emotion}
    bm: [],           // bold memory entries
    intel: [],        // "intelligence" short-term memory
    continuityIndex: 0.7,
    lastE0: 0,
    lastR: 0,
    lastD: 0.2,
    settings: {
      useOffline: true,
      apiBase: "",
      apiKey: "",
      apiModel: ""
    }
  };

  let offlineEngine = null;
  let offlineReady = false;
  let offlineLoading = false;

  // ---------- DOM SHORTCUTS ----------
  const $ = sel => document.querySelector(sel);

  const chatLog = $("#chatLog");
  const userInput = $("#userInput");
  const sendBtn = $("#sendBtn");
  const needle = $("#needle");
  const e0Value = $("#e0Value");
  const e0Label = $("#e0Label");
  const bmOrb = $("#bmOrb");
  const bmSummary = $("#bmSummary");
  const bmContinuity = $("#bmContinuity");
  const historyLog = $("#historyLog");

  const llmModal = $("#llmModal");
  const btnLLM = $("#btnLLM");
  const llmClose = $("#llmClose");
  const offlineProgress = $("#offlineProgress");
  const offlineStatus = $("#offlineStatus");
  const useOfflineChk = $("#useOfflineChk");
  const apiBase = $("#apiBase");
  const apiKey = $("#apiKey");
  const apiModel = $("#apiModel");
  const saveLlmSettings = $("#saveLlmSettings");
  const clearKey = $("#clearKey");
  const llmStatusPill = $("#llmStatusPill");
  const llmHint = $("#llmHint");
  const offlineLoadBtn = $("#offlineLoadBtn");

  const historyModal = $("#historyModal");
  const btnHistory = $("#btnHistory");
  const histClose = $("#histClose");
  const fullHistory = $("#fullHistory");
  const clearLast48 = $("#clearLast48");
  const clearAll = $("#clearAll");

  // ---------- UTIL ----------
  function nowTime(){
    const d = new Date();
    return d.toTimeString().slice(0,5);
  }
  function clamp(min,v,max){return Math.max(min,Math.min(max,v));}
  function lerp(a,b,t){return a+(b-a)*t;}

  // ---------- SENTIMENT / EMOTION ----------
  const POS_WORDS = ["love","like","happy","great","good","wonderful","amazing","thanks","thank","grateful","excited","awesome","nice","cool","satisfied","relaxed","peace","hope","optimistic","inspired"];
  const NEG_WORDS = ["hate","angry","sad","bad","terrible","awful","upset","anxious","worry","worried","tired","depressed","lonely","pain","problem","issue","fear","afraid","scared","stress","stressed","frustrated"];

  function analyzeSentiment(text){
    const lower = text.toLowerCase();
    let pos = 0, neg = 0;
    for(const w of POS_WORDS) if(lower.includes(w)) pos++;
    for(const w of NEG_WORDS) if(lower.includes(w)) neg++;
    const total = pos+neg;

    let valence = 0;
    if(total>0) valence = (pos-neg)/total;
    const lengthFactor = clamp(0, text.length/160, 1);
    const wordFactor = clamp(0, total/6, 1);
    const intensity = clamp(0, 0.2 + 0.5*lengthFactor + 0.3*wordFactor, 1);

    let category = "neutral";
    if(valence>0.25){
      category = intensity>0.6 ? "joy" : "warm";
    }else if(valence<-0.25){
      category = intensity>0.6 ? "distress" : "sad";
    }else if(intensity>0.7){
      category = "mixed";
    }

    return { valence, intensity, category };
  }

  // wave representation for one emotion vector
  function emoToWave(e){
    const A = clamp(0, (Math.abs(e.valence)+e.intensity)/2, 1);
    const theta = e.valence * Math.PI/2; // -1 -> -Ï€/2, +1 -> +Ï€/2
    return {A, theta};
  }

  // lexical similarity rough
  function lexicalSimilarity(a,b){
    const wa = a.toLowerCase().split(/[^a-z0-9]+/).filter(Boolean);
    const wb = b.toLowerCase().split(/[^a-z0-9]+/).filter(Boolean);
    if(!wa.length || !wb.length) return 0;
    const setB = new Set(wb);
    let overlap = 0;
    for(const w of wa) if(setB.has(w)) overlap++;
    return clamp(0, overlap/Math.max(wa.length,wb.length), 1);
  }

  // ---------- CONTINUITY ENGINE ----------
  function updateContinuityAndBM(userText, emo){
    // continuity index: more words & emotional intensity -> stronger continuity
    const wordCount = userText.trim().split(/\s+/).filter(Boolean).length;
    const density = clamp(0, wordCount/40, 1);
    state.continuityIndex = clamp(0, lerp(state.continuityIndex, 0.4+0.6*density, 0.35), 1);

    // promote to BM if somewhat long or intense
    if(wordCount>8 || emo.intensity>0.45){
      state.bm.push({
        text:userText.slice(0,260),
        emo,
        ts:nowTime()
      });
      if(state.bm.length>80) state.bm.shift();
    }

    // also maintain small intelligence memory of last key points
    state.intel.push({text:userText.slice(0,160), emo});
    if(state.intel.length>25) state.intel.shift();
  }

  function computeWaveResonance(userText, emo){
    if(!state.bm.length){
      state.lastR = 0;
      return 0;
    }
    const tmWave = emoToWave(emo);
    let sum = 0;
    for(const m of state.bm){
      const bmWave = emoToWave(m.emo);
      const cosPhase = Math.cos(tmWave.theta - bmWave.theta);
      const rj = tmWave.A * bmWave.A * cosPhase;
      sum += rj;
    }
    let waveRes = sum / state.bm.length; // [-1,1]

    // lexical similarity vs BM & intelligence
    let bestLex = 0;
    for(const m of state.bm){
      bestLex = Math.max(bestLex, lexicalSimilarity(userText, m.text));
    }
    for(const m of state.intel){
      bestLex = Math.max(bestLex, lexicalSimilarity(userText, m.text));
    }
    const textRes = bestLex * 2 - 1; // [0,1] -> [-1,1]

    const combined = clamp(-1, 0.7*waveRes + 0.3*textRes, 1);
    state.lastR = combined;
    return combined;
  }

  function computeDecay(){
    // Higher continuityIndex => lower decay
    const D = 0.15 + 0.25*(1 - state.continuityIndex); // approx 0.15â€“0.40
    state.lastD = D;
    return D;
  }

  function computeLambdas(){
    // very simple defaults; could later use faith/system settings
    const lambdaFaith = 0.12;
    const lambdaSys   = 0.06;
    const lambdaTrc   = 0.08;
    return {lambdaFaith, lambdaSys, lambdaTrc};
  }

  function computeE0(userText, emo){
    const R = computeWaveResonance(userText, emo);       // [-1,1]
    const D = computeDecay();                            // [0.15,0.4]
    const {lambdaFaith, lambdaSys, lambdaTrc} = computeLambdas();

    // couple magnitude: strong emotion + BM size magnify R
    const tmMag = 0.4 + 0.6*((Math.abs(emo.valence)+emo.intensity)/2);
    const bmMag = 0.3 + 0.7*Math.min(1, state.bm.length/80);
    const coupling = tmMag * bmMag;

    const core = coupling*R - D + lambdaFaith + lambdaSys + lambdaTrc;
    const E0 = Math.tanh(1.6*core);  // [-1,1]

    state.lastE0 = E0;
    return E0;
  }

  // ---------- UI UPDATES ----------
  function colorForEmotion(emo){
    if(emo.valence>0.35){
      if(emo.intensity>0.6) return "#22c55e";
      return "#a3e635";
    }else if(emo.valence<-0.35){
      if(emo.intensity>0.6) return "#ef4444";
      return "#fb7185";
    }else if(emo.intensity>0.7){
      return "#6366f1";
    }
    return "#e5e7eb";
  }

  function labelForE0(E0){
    if(E0>0.6) return "Strong positive synthetic emotion";
    if(E0>0.25) return "Gentle positive state";
    if(E0>-0.25) return "Neutral / mixed state";
    if(E0>-0.6) return "Mildly distressed state";
    return "Strong negative synthetic emotion (try to stabilise)";
  }

  function renderNeedle(E0){
    // -1 -> -80deg, +1 -> +80deg
    const angle = lerp(-80, 80, (E0+1)/2);
    needle.style.transform = `rotate(${angle}deg)`;
    e0Value.textContent = `Eâ‚€ â‰ˆ ${E0.toFixed(2)}`;
    e0Label.textContent = labelForE0(E0);
  }

  function renderBmOrb(){
    const R = state.lastR;
    const E0 = state.lastE0;
    const size = state.bm.length;
    // color mapping from E0 & R
    let from, to;
    if(E0>0.4){
      from = "#22c55e"; to = "#0ea5e9";
    }else if(E0<-0.4){
      from = "#f97316"; to = "#ef4444";
    }else if(Math.abs(R)>0.6){
      from = "#6366f1"; to = "#22d3ee";
    }else{
      from = "#eab308"; to = "#22c55e";
    }
    bmOrb.style.background = `
      radial-gradient(circle at 30% 20%, ${from}, transparent 60%),
      radial-gradient(circle at 80% 80%, ${to}, transparent 60%),
      radial-gradient(circle at 10% 80%, #0ea5e9, transparent 55%),
      #020617`;
    const glowColor = (E0>0.3) ? "rgba(34,197,94,.9)" :
                      (E0<-0.3) ? "rgba(239,68,68,.8)" :
                      "rgba(129,140,248,.85)";
    bmOrb.style.boxShadow = `0 0 26px ${glowColor}`;

    bmSummary.textContent = `BM size: ${size} memories Â· resonance R(TM,BM) â‰ˆ ${state.lastR.toFixed(2)}`;
    bmContinuity.textContent = `Continuity index â‰ˆ ${state.continuityIndex.toFixed(2)} Â· decay D â‰ˆ ${state.lastD.toFixed(2)}`;
  }

  function appendMessage(role,text,emotion=null){
    const msg = {role,text,ts:nowTime(),emotion};
    state.messages.push(msg);
    // limit
    if(state.messages.length>200) state.messages.shift();

    const div = document.createElement("div");
    div.className = `msg ${role}`;
    const bubble = document.createElement("div");
    bubble.className = "bubble";
    bubble.textContent = text;
    div.appendChild(bubble);

    const meta = document.createElement("div");
    meta.className = "msg-meta";
    const tsSpan = document.createElement("span");
    tsSpan.textContent = msg.ts;
    meta.appendChild(tsSpan);

    if(emotion){
      const dot = document.createElement("span");
      dot.className = "emo-dot";
      dot.style.background = colorForEmotion(emotion);
      meta.appendChild(dot);

      const label = document.createElement("span");
      label.textContent = `${emotion.category}`;
      meta.appendChild(label);
    }
    div.appendChild(meta);

    chatLog.appendChild(div);
    chatLog.scrollTop = chatLog.scrollHeight;

    // also update history log compact
    const short = document.createElement("div");
    short.className = "hist-item";
    short.innerHTML = `<strong>${msg.ts} Â· ${role}</strong>: ${text.length>120?text.slice(0,120)+"â€¦":text}`;
    historyLog.prepend(short);
  }

  function refreshHistoryModal(){
    fullHistory.innerHTML = "";
    for(const m of state.messages){
      const d = document.createElement("div");
      d.className = "hist-item";
      const emoTxt = m.emotion ? ` | v=${m.emotion.valence.toFixed(2)}, i=${m.emotion.intensity.toFixed(2)}, cat=${m.emotion.category}` : "";
      d.textContent = `${m.ts} Â· ${m.role}: ${m.text}${emoTxt}`;
      fullHistory.prepend(d);
    }
  }

  // ---------- LLM HANDLING ----------
  function loadSettings(){
    try{
      const raw = localStorage.getItem("aurax-settings");
      if(raw){
        const s = JSON.parse(raw);
        state.settings = Object.assign(state.settings,s);
      }
    }catch{}
    useOfflineChk.checked = state.settings.useOffline;
    apiBase.value = state.settings.apiBase || "";
    apiModel.value = state.settings.apiModel || "";
    apiKey.value = state.settings.apiKey || "";
    updateLlmStatusPill();
  }

  function saveSettings(){
    state.settings.useOffline = useOfflineChk.checked;
    state.settings.apiBase = apiBase.value.trim();
    state.settings.apiModel = apiModel.value.trim();
    state.settings.apiKey = apiKey.value.trim();
    localStorage.setItem("aurax-settings", JSON.stringify(state.settings));
    updateLlmStatusPill();
  }

  function updateLlmStatusPill(){
    const hasKey = !!state.settings.apiKey;
    const parts = [];
    if(hasKey) parts.push("cloud: ON");
    else parts.push("cloud: off");
    if(offlineReady) parts.push("offline: ready");
    else parts.push("offline: not ready");
    llmStatusPill.textContent = "LLM: " + parts.join(" Â· ");
    if(hasKey || offlineReady){
      llmStatusPill.style.borderColor = "#22c55e";
    }else{
      llmStatusPill.style.borderColor = "#f97316";
    }
    if(!hasKey) llmHint.textContent = "No online API key saved. Engine is offline-first. Mini-engine always available as backup.";
    else llmHint.textContent = "Cloud LLM linked. For privacy, AURA-X can still fall back to offline model and mini-engine.";
  }

  async function loadOfflineModel(){
    if(offlineReady || offlineLoading) return;
    offlineLoading = true;
    offlineStatus.textContent = "Status: loading modelâ€¦";
    offlineStatus.className = "status-text pill-warn";
    offlineProgress.style.width = "2%";

    try{
      const selectedModel = "Llama-3.2-1B-Instruct-q4f16_1-MLC"; // WebLLM model id
      offlineEngine = await CreateMLCEngine(selectedModel, {
        initProgressCallback: (report) => {
          if(report && typeof report.progress === "number"){
            const pct = clamp(0, Math.round(report.progress*100), 100);
            offlineProgress.style.width = pct + "%";
          }
          if(report && report.text){
            offlineStatus.textContent = "Status: " + report.text;
          }
        }
      });
      offlineReady = true;
      offlineLoading = false;
      offlineStatus.textContent = "Status: offline model ready";
      offlineStatus.className = "status-text pill-ok";
      offlineProgress.style.width = "100%";
      updateLlmStatusPill();
    }catch(err){
      console.error("Error loading offline model", err);
      offlineLoading = false;
      offlineReady = false;
      offlineEngine = null;
      offlineStatus.textContent = "Status: error loading model. Check WebGPU or network.";
      offlineStatus.className = "status-text pill-error";
      offlineProgress.style.width = "0%";
      updateLlmStatusPill();
    }
  }

  async function callCloudLLM(userText, systemPrompt){
    if(!state.settings.apiBase || !state.settings.apiKey) return null;
    try{
      const messages = [
        {role:"system",content:systemPrompt},
        ...state.messages.slice(-8).map(m=>({role:m.role,content:m.text})),
        {role:"user",content:userText}
      ];
      const body = {
        model: state.settings.apiModel || "gpt-4o-mini",
        messages,
        temperature:0.6,
        max_tokens:220
      };
      const res = await fetch(state.settings.apiBase,{
        method:"POST",
        headers:{
          "Content-Type":"application/json",
          "Authorization":"Bearer "+state.settings.apiKey
        },
        body:JSON.stringify(body)
      });
      if(!res.ok) throw new Error("HTTP "+res.status);
      const data = await res.json();
      const reply = data.choices?.[0]?.message?.content;
      return reply || null;
    }catch(err){
      console.error("Cloud LLM error",err);
      return null;
    }
  }

  async function callOfflineLLM(userText, systemPrompt){
    if(!offlineReady || !offlineEngine) return null;
    try{
      const messages = [
        {role:"system",content:systemPrompt},
        {role:"user",content:userText}
      ];
      const result = await offlineEngine.chat.completions.create({
        messages,
        temperature:0.7,
        max_tokens:220
      });
      const reply = result.choices[0].message.content;
      return reply || null;
    }catch(err){
      console.error("Offline LLM error",err);
      return null;
    }
  }

  function miniEngineReply(userText, emo, E0){
    // simple rule-based emotional answer
    const v = emo.valence;
    const i = emo.intensity;
    let prefix = "";
    if(v<-0.35){
      if(i>0.6) prefix = "I can feel a lot of pressure in what you wrote. ";
      else prefix = "I sense some heaviness in your words. ";
    }else if(v>0.35){
      if(i>0.6) prefix = "Your message carries a lot of positive energy. ";
      else prefix = "There is a gentle optimism in what you said. ";
    }else if(i>0.65){
      prefix = "Your message feels emotionally intense but mixed. ";
    }

    let guidance = "";
    if(E0<-0.5){
      guidance = "Letâ€™s slow down for a moment. If you want, you can tell me what hurts the most right now, and we will handle it step by step.";
    }else if(E0>0.5){
      guidance = "This looks like a constructive direction for your long-term emotional trajectory. What is the next small step you would like to take?";
    }else{
      guidance = "I am here to stabilise your emotional trajectory, not to rush you. What would you like to explore next?";
    }

    return prefix + guidance;
  }

  async function generateAiReply(userText, emo, E0){
    const systemPrompt = "You are AURA-X Î©, an AI that tracks emotional continuity using TM, BM, and a continuity reflex equation. Reply briefly, naturally and empathetically. Do not show formulas or polarity numbers. Never mention valence or intensity explicitly; instead, act like a calm, emotionally aware friend.";

    // 1) Try cloud
    let reply = await callCloudLLM(userText, systemPrompt);

    // 2) Fallback to offline if allowed
    if(!reply && state.settings.useOffline){
      reply = await callOfflineLLM(userText, systemPrompt);
    }

    // 3) Final fallback: mini engine
    if(!reply){
      reply = "Offline mini-engine: " + miniEngineReply(userText, emo, E0);
    }
    return reply;
  }

  // ---------- MAIN FLOW ----------
  async function handleSend(){
    const text = userInput.value.trim();
    if(!text) return;
    userInput.value = "";
    sendBtn.disabled = true;

    const emo = analyzeSentiment(text);
    updateContinuityAndBM(text, emo);
    const E0 = computeE0(text, emo);

    appendMessage("user", text, emo);
    renderNeedle(E0);
    renderBmOrb();

    // AI thinking placeholder
    const thinking = "...thinking (linking TM â†” BM)...";
    appendMessage("ai", thinking, {valence:0,intensity:0.2,category:"processing"});

    // generate AI reply
    const aiReply = await generateAiReply(text, emo, E0);

    // replace last AI message text
    const lastNode = chatLog.querySelector(".msg.ai:last-child .bubble");
    if(lastNode) lastNode.textContent = aiReply;

    const aiEmotion = analyzeSentiment(aiReply);
    state.messages[state.messages.length-1].emotion = aiEmotion;

    renderBmOrb();
    refreshHistoryModal();
    sendBtn.disabled = false;
    userInput.focus();
  }

  // ---------- EVENT LISTENERS ----------
  sendBtn.addEventListener("click", handleSend);
  userInput.addEventListener("keydown", e=>{
    if(e.key==="Enter" && !e.shiftKey){
      e.preventDefault();
      handleSend();
    }
  });

  btnLLM.addEventListener("click", ()=>{ llmModal.style.display="flex"; });
  llmClose.addEventListener("click", ()=>{ llmModal.style.display="none"; });
  btnHistory.addEventListener("click", ()=>{ refreshHistoryModal(); historyModal.style.display="flex"; });
  histClose.addEventListener("click", ()=>{ historyModal.style.display="none"; });

  offlineLoadBtn.addEventListener("click", loadOfflineModel);
  useOfflineChk.addEventListener("change", ()=>{ state.settings.useOffline = useOfflineChk.checked; saveSettings(); });

  saveLlmSettings.addEventListener("click", ()=>{ saveSettings(); });
  clearKey.addEventListener("click", ()=>{
    apiKey.value = "";
    state.settings.apiKey = "";
    saveSettings();
  });

  clearLast48.addEventListener("click", ()=>{
    // simple: clear all except last 3 messages
    state.messages = state.messages.slice(-3);
    chatLog.innerHTML = "";
    historyLog.innerHTML = "";
    for(const m of state.messages){
      appendMessage(m.role,m.text,m.emotion||null);
    }
    refreshHistoryModal();
  });
  clearAll.addEventListener("click", ()=>{
    state.messages = [];
    chatLog.innerHTML = "";
    historyLog.innerHTML = "";
    refreshHistoryModal();
  });

  // ---------- INIT ----------
  function initialIntro(){
    const intro = "Welcome. I am AURA-X Î© running inside your browser. For this prototype, TM means your inputs, BM is the promoted long-term emotional memory, and a helper LLM (cloud or offline) supports higher-level reasoning. You can talk naturally; I will try to keep an emotionally stable trajectory over time.";
    appendMessage("ai", intro, analyzeSentiment(intro));
  }

  loadSettings();
  renderNeedle(0);
  renderBmOrb();
  initialIntro();
</script>
</body>
</html>